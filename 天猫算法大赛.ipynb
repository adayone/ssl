{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import numpy  as np\n",
      "from sklearn.datasets import load_svmlight_file\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.metrics import f1_score\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression as LR\n",
      "from sklearn.datasets import load_svmlight_file\n",
      "import sklearn.metrics as ms\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.svm import SVC\n",
      "import pandas\n",
      "import numpy\n",
      "from sklearn.preprocessing import StandardScaler, normalize\n",
      "\n",
      "train_x, train_y = load_svmlight_file(r\"/Users/haoyuanhu/Project/tmall-com/t_alibaba_train_data.csv\")\n",
      "test_x, test_x_y = load_svmlight_file(r\"/Users/haoyuanhu/Project/tmall-com/t_alibaba_predict_data 2.txt\")\n",
      "\n",
      "train_y[train_y == -1] = 0\n",
      "\n",
      "ss = StandardScaler(with_mean=False)\n",
      "#ss.fit(numpy.r_[train_x, test_x])\n",
      "train_scale_x = ss.fit_transform(train_x)\n",
      "test_scale_x = ss.fit_transform(test_x)\n",
      "print train_scale_x\n",
      "#clf = GradientBoostingClassifier(n_estimators=200, max_depth=3)\n",
      "#clf.fit(train_x_array, train_y)\n",
      "#clf = LR(class_weight={1:100000})\n",
      "#model.fit(train_x, train_y)\n",
      "#from sklearn.svm import LinearSVC\n",
      "#clf = LinearSVC(loss=\"l2\")\n",
      "clf = SVC(class_weight={1:100000}, probability=True)\n",
      "#X_train, X_test, y_train, y_test = train_test_split(train_scale_x, train_y, test_size=0.2, random_state=0)\n",
      "clf.fit(train_scale_x, train_y)\n",
      "#clf.fit(X_train, y_train)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn import preprocessing as pp\n",
      "from sklearn import cross_validation as cv\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "workDir = r'/Users/haoyuanhu/Project/tmall-com/'\n",
      "\n",
      "# Read data\n",
      "trainset = pd.read_csv(r\"/Users/haoyuanhu/Project/tmall-com/train.csv\", header=None)\n",
      "labels = pd.read_csv(r\"/Users/haoyuanhu/Project/tmall-com//trainLabels.csv\", header=None)\n",
      "testset = pd.read_csv(r\"/Users/haoyuanhu/Project/tmall-com//test.csv\", header=None)\n",
      "\n",
      "train_x, train_y = load_svmlight_file(workDir + \"/t_alibaba_train_data.csv\")\n",
      "test_x, test_y = load_svmlight_file(workDir + \"/t_alibaba_predict_data 2.txt\")\n",
      "\n",
      "\n",
      "train_x = np.asarray(train_x)\n",
      "train_y = np.asarray(train_y).ravel()\n",
      "test_x = np.asarray(test_x)\n",
      "print train_x\n",
      "# Scale data\n",
      "train_x = pp.scale(train_x)\n",
      "test_x = pp.scale(test_x,with_mean=False)\n",
      "\n",
      "# pca\n",
      "pca = PCA(n_components=12,whiten=True)\n",
      "test_x = pca.fit_transform(test_x)\n",
      "train_x = pca.transform(train_x)\n",
      "\n",
      "\n",
      "# Select features\n",
      "selector = ExtraTreesClassifier(random_state=0)\n",
      "train_x = selector.fit_transform(train_x, train_y)\n",
      "test_x = selector.transform(test_x)\n",
      "\n",
      "# cross\n",
      "params = dict(gamma=[0.277777777778],C=[1000000],scale_C=[True])\n",
      "classifier = SVC(C=8, gamma=0.17)\n",
      "scores = cv.cross_val_score(classifier, train_x, train_y, cv=30)\n",
      "print('Estimated score: %0.5f (+/- %0.5f)' % (scores.mean(), scores.std() / 2))\n",
      "\n",
      "# Predict and save\n",
      "test_y = classifier.fit(train_x, train_y).predict(test_x)\n",
      "test_y_df = pd.DataFrame(dict(Id = np.arange(1, test_y.shape[0]+1), Solution=test_y))\n",
      "test_y_df.to_csv(workDir + \"ali_svm_label.csv\",  header = True, index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "rollaxis: axis (0) must be >=0 and < 0",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-10-69af81afd60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Scale data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/scikit_learn-0.14.1-py2.7-macosx-10.9-intel.egg/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mscale\u001b[0;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mwarn_if_not_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'The scale function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         mean_, std_ = _mean_and_std(\n\u001b[0;32m--> 136\u001b[0;31m             X, axis, with_mean=with_mean, with_std=with_std)\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/scikit_learn-0.14.1-py2.7-macosx-10.9-intel.egg/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36m_mean_and_std\u001b[0;34m(X, axis, with_mean, with_std)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[1;32m     49\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mXr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mrollaxis\u001b[0;34m(a, axis, start)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rollaxis: %s (%d) must be >=0 and < %d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: rollaxis: axis (0) must be >=0 and < 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 0)\t2.63905732962\n",
        "  (0, 1)\t2.63905732962\n",
        "  (0, 2)\t2.63905732962\n",
        "  (0, 3)\t2.63905732962\n",
        "  (0, 4)\t2.63905732962\n",
        "  (0, 5)\t2.63905732962\n",
        "  (0, 6)\t0.69314718056\n",
        "  (0, 7)\t0.69314718056\n",
        "  (0, 8)\t0.69314718056\n",
        "  (0, 9)\t0.69314718056\n",
        "  (0, 10)\t0.69314718056\n",
        "  (0, 11)\t0.69314718056\n",
        "  (1, 0)\t3.91202300543\n",
        "  (1, 1)\t3.93182563272\n",
        "  (1, 2)\t4.06044301055\n",
        "  (1, 3)\t4.39444915467\n",
        "  (1, 4)\t4.39444915467\n",
        "  (1, 5)\t4.39444915467\n",
        "  (1, 6)\t0.69314718056\n",
        "  (1, 7)\t0.69314718056\n",
        "  (1, 8)\t0.69314718056\n",
        "  (1, 9)\t0.69314718056\n",
        "  (1, 10)\t0.69314718056\n",
        "  (1, 11)\t0.69314718056\n",
        "  (2, 0)\t5.43807930892\n",
        "  :\t:\n",
        "  (58986, 29)\t0.69314718056\n",
        "  (58986, 35)\t0.69314718056\n",
        "  (58987, 29)\t0.69314718056\n",
        "  (58987, 35)\t0.69314718056\n",
        "  (58988, 29)\t0.69314718056\n",
        "  (58988, 35)\t0.69314718056\n",
        "  (58989, 24)\t0.69314718056\n",
        "  (58989, 25)\t0.69314718056\n",
        "  (58989, 26)\t0.69314718056\n",
        "  (58989, 27)\t0.69314718056\n",
        "  (58989, 28)\t1.09861228867\n",
        "  (58989, 29)\t1.60943791243\n",
        "  (58989, 35)\t0.69314718056\n",
        "  (58990, 27)\t0.69314718056\n",
        "  (58990, 28)\t0.69314718056\n",
        "  (58990, 29)\t1.38629436112\n",
        "  (58990, 35)\t0.69314718056\n",
        "  (58991, 29)\t0.69314718056\n",
        "  (58991, 35)\t0.69314718056\n",
        "  (58992, 29)\t0.69314718056\n",
        "  (58992, 35)\t0.69314718056\n",
        "  (58993, 29)\t0.69314718056\n",
        "  (58993, 35)\t0.69314718056\n",
        "  (58994, 29)\t0.69314718056\n",
        "  (58994, 35)\t0.69314718056\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "train_x, train_y = load_svmlight_file(r\"/Users/haoyuanhu/Project/tmall-com/t_alibaba_train_data.csv\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "train_y[train_y == -1] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(train_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=0)\n",
      "clf = SVC(probability=True)\n",
      "clf.fit(X_train, y_train) \n",
      "clf.score(X_test, y_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "y_test_predict = clf.predict(X_test)\n",
      "f1_score(y_test, y_test_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_x, test_y = load_svmlight_file(r\"/Users/haoyuanhu/Project/tmall-com/t_alibaba_predict_data.txt\")\n",
      "test_y = clf.predict_proba(test_x)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(test_y)\n",
      "print test_y, test_y[:,1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score = test_y[:,1]\n",
      "print np.sum(score > 0), np.sum(score > 0.03)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "id_y = pandas.read_csv(r\"/Users/haoyuanhu/Project/tmall-com/t_alibaba_ub_data.txt\", sep=\" \", header=None)\n",
      "id_y[\"2\"] = score\n",
      "\n",
      "#test_y_df = pandas.DataFrame(dict(Id = np.arange(1, test_y.shape[0]+1), Solution=test_y))\n",
      "#test_y_df.to_csv(r\"/Users/haoyuanhu/Project/tmall-com/svm_alibaba.csv\",  header = True, index=False)\n",
      "id_y.to_csv(r\"/Users/haoyuanhu/Project/tmall-com/alibaba_svm_res.csv\", header=None, index=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_brand = id_y.groupby(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = pandas.DataFrame(columns=('user', 'brands'))\n",
      "for user, group in user_brand:\n",
      "    top = group.sort(\"2\", ascending=False )[:2]\n",
      "    np.asarray(top)\n",
      "    brands = \",\".join(map(str, list(top[1]))))\n",
      "    res = res.append(row)\n",
      "    #print top.keys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res.to_csv(r\"/Users/haoyuanhu/Project/tmall-com/alibaba_svm_res.csv\", cols=(\"user\",\"brands\"),index=None, header=None, sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res.to_csv(r\"/Users/haoyuanhu/Project/tmall-com/alibaba_svm_res.csv\", sep=\"\\t\", index=None, header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "svc = SVC(probability=True)\n",
      "C_range = 2.0 ** np.arange(-3, 2)\n",
      "gamma_range = 2.0 ** np.arange(-3, 2)\n",
      "\n",
      "param_grid = dict(gamma=gamma_range, C=C_range)\n",
      "\n",
      "best_clf = GridSearchCV(svc, param_grid=param_grid, scoring = 'f1',cv=10, n_jobs=-1)\n",
      "best_clf.fit(train_x, train_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "import numpy as np\n",
      "from sklearn.datasets import load_svmlight_file\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "depth = np.arange(1, 3)\n",
      "train_x, train_y = load_svmlight_file(r\"/Users/haoyuanhu/Project/tmall-com/t_alibaba_train_data.csv\")\n",
      "train_y[train_y == -1] = 0\n",
      "gbrt = GradientBoostingClassifier(n_estimators=200)\n",
      "best_clf = GridSearchCV(gbrt, param_grid={\"max_depth\":depth}, scoring = 'f1', cv=10, n_jobs=-1)\n",
      "best_clf.fit(train_x, train_y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}